
ğŸ” Real-Time Object Detection with TFLite + OpenCV
This project uses TensorFlow Lite, OpenCV, and optional NPU acceleration to perform real-time object detection using a quantized MobileNet SSD model.

ğŸ“¦ Requirements
Install dependencies:

bash
Copy
Edit
pip install opencv-python pillow numpy tflite-runtime
âœ… Python 3.6+ required

Libraries Used:

ğŸ–¼ï¸ opencv-python â€“ Video stream handling & display

ğŸ§® numpy â€“ Numerical operations

ğŸ–Œï¸ pillow â€“ Image utilities

ğŸ§  tflite-runtime â€“ Efficient TFLite model inference

ğŸš€ How to Run
ğŸ–¥ï¸ 1. Default Camera (Index 1)
bash
Copy
Edit
python detect.py
ğŸ¥ 2. Custom Camera or Video File
bash
Copy
Edit
# Camera index 0
python detect.py -i 0

# Video file
python detect.py -i path/to/video.mp4
âš¡ 3. With Hardware Acceleration (e.g., NPU/GPU)
bash
Copy
Edit
python detect.py -d libvx_delegate.so
âœ… Make sure libvx_delegate.so exists on your device.

ğŸ§¾ Label Mapping (labels.py)
Create a labels.py file with:

python
Copy
Edit
label2string = {
    0: 'person',
    1: 'car',
    2: 'bicycle',
    3: 'motorcycle',
    4: 'airplane',
    5: 'bus',
    # ... add more as needed
}
ğŸ” Must match the modelâ€™s class indices.

ğŸ¯ What You'll See
âœ… Real-time Output
ğŸŸ¥ Bounding Boxes

ğŸ·ï¸ Class Labels

ğŸ“Š FPS and Inference Time

ğŸ’¬ Console Example
text
Copy
Edit
Detection: (84, 130)-(210, 310) Label: person
FPS: 26  Inference: 15ms
ğŸªŸ Display
A window shows the video feed with object detections.

Press q to exit.

ğŸ” Under the Hood
Open video source (camera or file)

Load .tflite model (optionally with delegate)

Resize frame to model input size

Run inference

Parse output:

Get bounding boxes & labels

Draw overlays

Show FPS & timing

Loop till you quit

ğŸ’¡ Tips & Tricks
Use quantized TFLite models (uint8) for NPU/GPU compatibility.

For NXP i.MX8MP, use libvx_delegate.so to run inference on the NPU.

Improve FPS by:

Reducing video resolution

Choosing lighter models

Using efficient delegates

Let me know if you'd like this saved as a file or turned into a GitHub Gist!
